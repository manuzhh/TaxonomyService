{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "# This notebook is meant to help you set up the service for production use and/or do some configuration tests\n",
    "#############################################################################################################\n",
    "\n",
    "# imports\n",
    "from ConfigReader import ConfigReader\n",
    "from SetupRunner import SetupRunner\n",
    "\n",
    "# this sets the config settings to a 'best performing' setting, based on tests previously made by the developer\n",
    "ConfigReader.set_to_best_performing()\n",
    "\n",
    "# you can also set the settings to a specific config by passing a config identifier\n",
    "#session_config_id = 'session_configs/conf1'\n",
    "#ConfigReader.set_session_config_id(session_config_id)\n",
    "\n",
    "# with these lines you set up the service, up to (but not including) the classifier\n",
    "SetupRunner.run_setup(run_import=1, run_preprocessing=0, run_vectorization=0, run_classification=0)\n",
    "SetupRunner.run_setup(run_import=0, run_preprocessing=1, run_vectorization=0, run_classification=0)\n",
    "SetupRunner.run_setup(run_import=0, run_preprocessing=0, run_vectorization=1, run_classification=0)\n",
    "\n",
    "# at this point you can choose wether to set up the classifier for production use\n",
    "# or split the corpus into train and test set to do some config testing for the classifier\n",
    "\n",
    "# set up classifier for production use\n",
    "SetupRunner.run_setup(run_import=0, run_preprocessing=0, run_vectorization=0, run_classification=1)\n",
    "\n",
    "# instead of making the previous setup calls you can also combine them into one call\n",
    "#SetupRunner.run_setup(run_import=1, run_preprocessing=1, run_vectorization=1, run_classification=1)\n",
    "# or\n",
    "#SetupRunner.run_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a config test for the classifier\n",
    "#SetupRunner.run_classification_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load evaluations, containing the result of the previously run test\n",
    "#from EvaluationHandler import EvaluationHandler\n",
    "#EvaluationHandler.load_evaluations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also run a number of config tests, based on the project's config template\n",
    "# use with caution, though: this may take a few hours, depending on your system...\n",
    "#SetupRunner.run_config_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can resume the config tests at any point by specifying a config index (i.e. if the notebook crashed)\n",
    "# check the session's log file to see at which index testing previously stopped\n",
    "#idx = 50\n",
    "#SetupRunner.resume_config_tests_at_idx(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when you are done testing you can simply run any of the setup steps again (i.e. setting up the classifier)\n",
    "#SetupRunner.run_setup(run_import=0, run_preprocessing=0, run_vectorization=0, run_classification=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
